[2021-03-15 08:28:49,450 INFO] Device ID 0
[2021-03-15 08:28:49,451 INFO] Device cuda
[2021-03-15 08:28:49,492 INFO] Loading checkpoint from ../baseline_models/model_step_18000.pt
[2021-03-15 08:28:50,196 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2021-03-15 08:28:50,197 INFO] Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2021-03-15 08:28:50,228 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2021-03-15 08:28:54,827 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (dropout): Dropout(p=0.1)
    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-03-15 08:28:54,832 INFO] * number of parameters: 120512513
[2021-03-15 08:28:54,833 INFO] Start training...
[2021-03-15 08:28:54,882 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 08:30:52,351 INFO] Step 18050/50000; xent: 0.64; lr: 0.0000149;   9 docs/s;    117 sec
[2021-03-15 08:32:40,794 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 08:32:50,143 INFO] Step 18100/50000; xent: 0.64; lr: 0.0000149;  10 docs/s;    235 sec
[2021-03-15 08:34:49,483 INFO] Step 18150/50000; xent: 0.54; lr: 0.0000148;  10 docs/s;    355 sec
[2021-03-15 08:36:31,269 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 08:36:48,039 INFO] Step 18200/50000; xent: 0.61; lr: 0.0000148;  10 docs/s;    473 sec
[2021-03-15 08:38:46,428 INFO] Step 18250/50000; xent: 0.45; lr: 0.0000148;   9 docs/s;    592 sec
[2021-03-15 08:40:19,743 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 08:40:45,758 INFO] Step 18300/50000; xent: 0.47; lr: 0.0000148;  10 docs/s;    711 sec
[2021-03-15 08:40:45,760 INFO] Saving checkpoint ../trial_clean5/clean5_models/model_step_18300.pt
[2021-03-15 08:42:46,029 INFO] Step 18350/50000; xent: 0.28; lr: 0.0000148;  10 docs/s;    831 sec
[2021-03-15 08:44:12,094 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 08:44:45,880 INFO] Step 18400/50000; xent: 0.31; lr: 0.0000147;   9 docs/s;    951 sec
[2021-03-15 08:46:44,661 INFO] Step 18450/50000; xent: 0.18; lr: 0.0000147;  10 docs/s;   1070 sec
[2021-03-15 08:48:00,763 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 08:48:43,967 INFO] Step 18500/50000; xent: 0.19; lr: 0.0000147;   9 docs/s;   1189 sec
[2021-03-15 08:50:42,300 INFO] Step 18550/50000; xent: 0.05; lr: 0.0000147;  10 docs/s;   1307 sec
[2021-03-15 08:51:51,420 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 08:52:42,024 INFO] Step 18600/50000; xent: 0.07; lr: 0.0000147;  10 docs/s;   1427 sec
[2021-03-15 08:52:42,027 INFO] Saving checkpoint ../trial_clean5/clean5_models/model_step_18600.pt
[2021-03-15 08:54:41,454 INFO] Step 18650/50000; xent: 0.08; lr: 0.0000146;  10 docs/s;   1547 sec
[2021-03-15 08:55:40,879 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 08:56:39,240 INFO] Step 18700/50000; xent: 0.08; lr: 0.0000146;  10 docs/s;   1664 sec
[2021-03-15 08:58:38,082 INFO] Step 18750/50000; xent: 0.05; lr: 0.0000146;  10 docs/s;   1783 sec
[2021-03-15 08:59:30,435 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 09:00:36,305 INFO] Step 18800/50000; xent: 0.04; lr: 0.0000146;  10 docs/s;   1901 sec
[2021-03-15 09:02:34,439 INFO] Step 18850/50000; xent: 0.03; lr: 0.0000146;  10 docs/s;   2020 sec
[2021-03-15 09:03:17,597 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 09:04:33,527 INFO] Step 18900/50000; xent: 0.04; lr: 0.0000145;  10 docs/s;   2139 sec
[2021-03-15 09:04:33,529 INFO] Saving checkpoint ../trial_clean5/clean5_models/model_step_18900.pt
[2021-03-15 09:06:32,765 INFO] Step 18950/50000; xent: 0.04; lr: 0.0000145;   9 docs/s;   2258 sec
[2021-03-15 09:07:08,309 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 09:08:30,710 INFO] Step 19000/50000; xent: 0.03; lr: 0.0000145;  10 docs/s;   2376 sec
[2021-03-15 09:10:28,941 INFO] Step 19050/50000; xent: 0.02; lr: 0.0000145;  10 docs/s;   2494 sec
[2021-03-15 09:10:55,587 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 09:12:27,403 INFO] Step 19100/50000; xent: 0.02; lr: 0.0000145;  10 docs/s;   2613 sec
[2021-03-15 09:14:25,782 INFO] Step 19150/50000; xent: 0.01; lr: 0.0000145;  10 docs/s;   2731 sec
[2021-03-15 09:14:44,848 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
[2021-03-15 09:16:23,756 INFO] Step 19200/50000; xent: 0.05; lr: 0.0000144;   9 docs/s;   2849 sec
[2021-03-15 09:16:23,758 INFO] Saving checkpoint ../trial_clean5/clean5_models/model_step_19200.pt
[2021-03-15 09:18:23,762 INFO] Step 19250/50000; xent: 0.05; lr: 0.0000144;  10 docs/s;   2969 sec
[2021-03-15 09:18:33,433 INFO] Loading train dataset from ../trial_clean5/clean5_data2/train.0.bert.pt, number of examples: 1111
