[2021-03-15 23:19:09,465 INFO] Device ID 0
[2021-03-15 23:19:09,465 INFO] Device cuda
[2021-03-15 23:19:09,501 INFO] Loading checkpoint from ../baseline_models/model_step_18000.pt
[2021-03-15 23:19:10,199 INFO] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at ../temp/4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517
[2021-03-15 23:19:10,199 INFO] Model config {
  "architectures": [
    "BertForMaskedLM"
  ],
  "attention_probs_dropout_prob": 0.1,
  "finetuning_task": null,
  "hidden_act": "gelu",
  "hidden_dropout_prob": 0.1,
  "hidden_size": 768,
  "initializer_range": 0.02,
  "intermediate_size": 3072,
  "layer_norm_eps": 1e-12,
  "max_position_embeddings": 512,
  "model_type": "bert",
  "num_attention_heads": 12,
  "num_hidden_layers": 12,
  "num_labels": 2,
  "output_attentions": false,
  "output_hidden_states": false,
  "pad_token_id": 0,
  "pruned_heads": {},
  "torchscript": false,
  "type_vocab_size": 2,
  "vocab_size": 30522
}

[2021-03-15 23:19:10,226 INFO] loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-pytorch_model.bin from cache at ../temp/aa1ef1aede4482d0dbcd4d52baad8ae300e60902e88fcb0bebdec09afd232066.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157
[2021-03-15 23:19:14,922 INFO] ExtSummarizer(
  (bert): Bert(
    (model): BertModel(
      (embeddings): BertEmbeddings(
        (word_embeddings): Embedding(30522, 768, padding_idx=0)
        (position_embeddings): Embedding(512, 768)
        (token_type_embeddings): Embedding(2, 768)
        (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (encoder): BertEncoder(
        (layer): ModuleList(
          (0): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (1): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (2): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (3): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (4): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (5): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (6): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (7): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (8): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (9): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (10): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
          (11): BertLayer(
            (attention): BertAttention(
              (self): BertSelfAttention(
                (query): Linear(in_features=768, out_features=768, bias=True)
                (key): Linear(in_features=768, out_features=768, bias=True)
                (value): Linear(in_features=768, out_features=768, bias=True)
                (dropout): Dropout(p=0.1)
              )
              (output): BertSelfOutput(
                (dense): Linear(in_features=768, out_features=768, bias=True)
                (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
                (dropout): Dropout(p=0.1)
              )
            )
            (intermediate): BertIntermediate(
              (dense): Linear(in_features=768, out_features=3072, bias=True)
            )
            (output): BertOutput(
              (dense): Linear(in_features=3072, out_features=768, bias=True)
              (LayerNorm): LayerNorm(torch.Size([768]), eps=1e-12, elementwise_affine=True)
              (dropout): Dropout(p=0.1)
            )
          )
        )
      )
      (pooler): BertPooler(
        (dense): Linear(in_features=768, out_features=768, bias=True)
        (activation): Tanh()
      )
    )
  )
  (ext_layer): ExtTransformerEncoder(
    (pos_emb): PositionalEncoding(
      (dropout): Dropout(p=0.1)
    )
    (transformer_inter): ModuleList(
      (0): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
      (1): TransformerEncoderLayer(
        (self_attn): MultiHeadedAttention(
          (linear_keys): Linear(in_features=768, out_features=768, bias=True)
          (linear_values): Linear(in_features=768, out_features=768, bias=True)
          (linear_query): Linear(in_features=768, out_features=768, bias=True)
          (softmax): Softmax()
          (dropout): Dropout(p=0.1)
          (final_linear): Linear(in_features=768, out_features=768, bias=True)
        )
        (feed_forward): PositionwiseFeedForward(
          (w_1): Linear(in_features=768, out_features=2048, bias=True)
          (w_2): Linear(in_features=2048, out_features=768, bias=True)
          (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
          (dropout_1): Dropout(p=0.1)
          (dropout_2): Dropout(p=0.1)
        )
        (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
        (dropout): Dropout(p=0.1)
      )
    )
    (dropout): Dropout(p=0.1)
    (layer_norm): LayerNorm(torch.Size([768]), eps=1e-06, elementwise_affine=True)
    (wo): Linear(in_features=768, out_features=1, bias=True)
    (sigmoid): Sigmoid()
  )
)
[2021-03-15 23:19:14,929 INFO] * number of parameters: 120512513
[2021-03-15 23:19:14,929 INFO] Start training...
[2021-03-15 23:19:15,009 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.0.bert.pt, number of examples: 1846
[2021-03-15 23:21:05,131 INFO] Step 18050/50000; xent: 0.39; lr: 0.0000149;  10 docs/s;    110 sec
[2021-03-15 23:22:58,452 INFO] Step 18100/50000; xent: 0.36; lr: 0.0000149;  11 docs/s;    223 sec
[2021-03-15 23:24:52,196 INFO] Step 18150/50000; xent: 0.44; lr: 0.0000148;  10 docs/s;    337 sec
[2021-03-15 23:25:10,321 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.1.bert.pt, number of examples: 337
[2021-03-15 23:26:14,768 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.0.bert.pt, number of examples: 1846
[2021-03-15 23:26:44,211 INFO] Step 18200/50000; xent: 0.20; lr: 0.0000148;  10 docs/s;    449 sec
[2021-03-15 23:28:38,242 INFO] Step 18250/50000; xent: 0.30; lr: 0.0000148;  10 docs/s;    563 sec
[2021-03-15 23:30:30,508 INFO] Step 18300/50000; xent: 0.45; lr: 0.0000148;  10 docs/s;    675 sec
[2021-03-15 23:30:30,511 INFO] Saving checkpoint ../trial_clean_aug6/clean_aug6_models/model_step_18300.pt
[2021-03-15 23:32:16,313 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.1.bert.pt, number of examples: 337
[2021-03-15 23:32:24,380 INFO] Step 18350/50000; xent: 0.28; lr: 0.0000148;  11 docs/s;    789 sec
[2021-03-15 23:33:20,647 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.1.bert.pt, number of examples: 337
[2021-03-15 23:34:16,141 INFO] Step 18400/50000; xent: 0.00; lr: 0.0000147;  10 docs/s;    901 sec
[2021-03-15 23:34:27,410 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.0.bert.pt, number of examples: 1846
[2021-03-15 23:36:09,541 INFO] Step 18450/50000; xent: 0.26; lr: 0.0000147;  10 docs/s;   1015 sec
[2021-03-15 23:38:03,307 INFO] Step 18500/50000; xent: 0.26; lr: 0.0000147;  11 docs/s;   1128 sec
[2021-03-15 23:39:57,160 INFO] Step 18550/50000; xent: 0.30; lr: 0.0000147;  10 docs/s;   1242 sec
[2021-03-15 23:40:26,076 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.1.bert.pt, number of examples: 337
[2021-03-15 23:41:30,461 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.0.bert.pt, number of examples: 1846
[2021-03-15 23:41:48,667 INFO] Step 18600/50000; xent: 0.10; lr: 0.0000147;  10 docs/s;   1354 sec
[2021-03-15 23:41:48,669 INFO] Saving checkpoint ../trial_clean_aug6/clean_aug6_models/model_step_18600.pt
[2021-03-15 23:43:43,747 INFO] Step 18650/50000; xent: 0.20; lr: 0.0000146;  10 docs/s;   1469 sec
[2021-03-15 23:45:37,540 INFO] Step 18700/50000; xent: 0.17; lr: 0.0000146;  10 docs/s;   1583 sec
[2021-03-15 23:47:30,313 INFO] Step 18750/50000; xent: 0.15; lr: 0.0000146;  10 docs/s;   1695 sec
[2021-03-15 23:47:30,466 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.1.bert.pt, number of examples: 337
[2021-03-15 23:48:37,008 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.0.bert.pt, number of examples: 1846
[2021-03-15 23:49:22,407 INFO] Step 18800/50000; xent: 0.03; lr: 0.0000146;  10 docs/s;   1807 sec
[2021-03-15 23:51:14,567 INFO] Step 18850/50000; xent: 0.10; lr: 0.0000146;  11 docs/s;   1920 sec
[2021-03-15 23:53:08,276 INFO] Step 18900/50000; xent: 0.08; lr: 0.0000145;  10 docs/s;   2033 sec
[2021-03-15 23:53:08,278 INFO] Saving checkpoint ../trial_clean_aug6/clean_aug6_models/model_step_18900.pt
[2021-03-15 23:54:36,108 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.0.bert.pt, number of examples: 1846
[2021-03-15 23:55:02,656 INFO] Step 18950/50000; xent: 0.11; lr: 0.0000145;  10 docs/s;   2148 sec
[2021-03-15 23:56:56,774 INFO] Step 19000/50000; xent: 0.05; lr: 0.0000145;  10 docs/s;   2262 sec
[2021-03-15 23:58:50,625 INFO] Step 19050/50000; xent: 0.03; lr: 0.0000145;  10 docs/s;   2376 sec
[2021-03-16 00:00:34,555 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.1.bert.pt, number of examples: 337
[2021-03-16 00:00:43,557 INFO] Step 19100/50000; xent: 0.08; lr: 0.0000145;  10 docs/s;   2489 sec
[2021-03-16 00:01:41,334 INFO] Loading train dataset from ../trial_clean_aug6/clean_aug6_data2/train.0.bert.pt, number of examples: 1846
[2021-03-16 00:02:36,076 INFO] Step 19150/50000; xent: 0.02; lr: 0.0000145;  10 docs/s;   2601 sec
[2021-03-16 00:04:29,006 INFO] Step 19200/50000; xent: 0.03; lr: 0.0000144;  10 docs/s;   2714 sec
[2021-03-16 00:04:29,009 INFO] Saving checkpoint ../trial_clean_aug6/clean_aug6_models/model_step_19200.pt
[2021-03-16 00:06:24,715 INFO] Step 19250/50000; xent: 0.02; lr: 0.0000144;  10 docs/s;   2830 sec
