[privacy & terms](/ "privacy & terms")

[](https://www.google.com/intl/en/about/products)

[sign
in](https://accounts.google.com/servicelogin?passive=1209600&continue=https://policies.google.com/technologies/anonymization?hl%3den&followup=https://policies.google.com/technologies/anonymization?hl%3den&hl=en&ec=gazaoqq)

  * [overview](?hl=en)
  * [privacy policy](privacy?hl=en)
  * [terms of service](terms?hl=en)
  * [technologies](technologies?hl=en)
  * [faq](faq?hl=en)

#
[![google](https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_74x24dp.png)](https://www.google.com/?hl=en)

# privacy & terms

  * [overview](?hl=en)
  * [privacy policy](privacy?hl=en)
  * [terms of service](terms?hl=en)
  * [technologies](technologies?hl=en)
    * [advertising](technologies/ads?hl=en)
    * [how google uses cookies](technologies/cookies?hl=en)
    * [how google uses pattern recognition](technologies/pattern-recognition?hl=en)
    * [how google uses location information](technologies/location-data?hl=en)
    * [how google uses credit card numbers for payments](technologies/wallet?hl=en)
    * [how google voice works](technologies/voice?hl=en)
    * [google product privacy guide](technologies/product-privacy?hl=en)
    * [how google retains data we collect](technologies/retention?hl=en)
      * [how google anonymizes data](technologies/anonymization?hl=en)
  * [faq](faq?hl=en)

[privacy & terms](/ "privacy & terms")

#
[![google](https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_74x24dp.png)](https://www.google.com/?hl=en)

## [privacy & terms](?hl=en)

  * [overview](?hl=en)
  * [privacy policy](privacy?hl=en)
  * [terms of service](terms?hl=en)
  * [technologies](technologies?hl=en)
  * [faq](faq?hl=en)
  * [google account](https://myaccount.google.com/?hl=en)

  * [technologies](technologies?hl=en)
  * [advertising](technologies/ads?hl=en)
  * [how google uses cookies](technologies/cookies?hl=en)
  * [how google uses pattern recognition](technologies/pattern-recognition?hl=en)
  * [how google uses location information](technologies/location-data?hl=en)
  * [how google uses credit card numbers for payments](technologies/wallet?hl=en)
  * [how google voice works](technologies/voice?hl=en)
  * [google product privacy guide](technologies/product-privacy?hl=en)
  * [how google retains data we collect](technologies/retention?hl=en)
    * how google anonymizes data

# how google anonymizes data

anonymization is a data processing technique that removes or modifies
personally identifiable information; it results in anonymized data that cannot
be associated with any one individual. it’s also a critical component of
google’s commitment to privacy.

by analyzing anonymized data, we are able to build safe and valuable products
and features, like autocompletion of an entered search query, and better
detect security threats, like phishing and malware sites, all while protecting
user identities. we can also safely share anonymized data externally, making
it useful for others without putting the privacy of our users at risk.

## two of the techniques we use to protect your data

### generalizing the data

there are certain data elements that are more easily connected to certain
individuals. in order to protect those individuals, we use generalization to
remove a portion of the data or replace some part of it with a common value.
for example, we may use generalization to replace segments of all area codes
or phone numbers with the same sequence of numbers.

generalization allows us to achieve k-anonymity, an industry-standard term
used to describe a technique for hiding the identity of individuals in a group
of similar persons. in k-anonymity, the k is a number that represents the size
of a group. if for any individual in the data set, there are at least k-1
individuals who have the same properties, then we have achieved k-anonymity
for the data set. for example, imagine a certain data set where k equals 50
and the property is zip code. if we look at any person within that data set,
we will always find 49 others with the same zip code. therefore, we would not
be able to identify any one person from just their zip code.

if all individuals in a data set share the same value of a sensitive
attribute, sensitive information may be revealed simply by knowing these
individuals are part of the data set in question. to mitigate this risk, we
may leverage l-diversity, an industry-standard term used to describe some
level of diversity in the sensitive values. for example, imagine a group of
people searched for the same sensitive health topic (e.g. flu symptoms) all at
the same time. if we look at this data set, we wouldn’t be able to tell who
searched for the topic, thanks to k-anonymity. however, there may still be a
privacy concern since everyone shares a sensitive attribute (i.e. the topic of
the query). l-diversity means the anonymized data set would not only contain
flu searches. rather, it could include other searches alongside the flu
searches to further protect user privacy.

### adding noise to data

differential privacy (also an industry-standard term) describes a technique
for adding mathematical noise to data. with differential privacy, it’s
difficult to ascertain whether any one individual is part of a data set
because the output of a given algorithm will essentially appear the same,
regardless of whether any one individual’s information is included or omitted.
for example, imagine we are measuring the overall trend in searches for flu
across a geographic region. to achieve differential privacy, we add noise to
the data set. this means we may add or subtract the number of people searching
for flu in a given neighborhood, but doing so would not affect our measurement
of the trend across the broader geographic region. it’s also important to note
that adding noise to a data set may render it less useful.

anonymization is just one process we use to maintain our commitment to user
privacy. other processes include strict controls on user data access, policies
to control and limit joining of data sets that may identify users, and the
centralized review of anonymization and data governance strategies to ensure a
consistent level of protection across all of google.

change language:afrikaansbahasa indonesiabahasa
melayucatalàčeštinadanskdeutscheestienglishenglish (united
kingdom)españolespañol (latinoamérica)euskarafilipinofrançaisfrançais
(canada)galegohrvatskiisizuluíslenskaitalianokiswahililatviešulietuviųmagyarnederlandsnorskpolskiportuguês
(brasil)português (portugal)românăslovenčinaslovenščinasrpskisuomisvenskatiếng
việttürkçeελληνικάбългарскирусскийсрпскиукраїнська‫עברית‬‫اردو‬‫العربية‬‫فارسی‬አማርኛमराठीहिन्दीবাংলাગુજરાતીதமிழ்తెలుగుಕನ್ನಡമലയാളംไทย한국어中文
(香港)中文（简体中文）中文（繁體中文）日本語

  * [google](https://www.google.com/)
  * [about google](https://about.google/)
  * [privacy](privacy?hl=en)
  * [terms](terms?hl=en)

google apps

main menu

